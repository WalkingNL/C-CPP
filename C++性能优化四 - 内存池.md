## Memory pool
### 前言
内存**池**的存在，实际上是**集中**化了程序的**动态**特性，所以程序的执行效率才能更高，内存的可用性才会更好。这句话别人看了之后，可能不知道我在说什么。这里不妨先举个生活中的例子，供参考。我们有一句话是这么说的：**好借好还，再借不难**，这句话大多数人都应该听过的吧。现在如果有一个人每天早上都向你借10块钱，到了晚上再还你，我不知到你作何感受。再假如如果你兜里没有10块的零钱，你还得去换些。当然了，作为我们人来说，算了，没零钱，我要么全给你，要么不借你了。但对于内存分配而言，只要内存足够，他必须按照你的需求，一次要多少，就给你多少(先不考虑内存对齐的问题)。如果空闲块没有合适大小的，就找大的内存块，进行切割。用完了之后，再还回来。而且还回来的，是零碎的。想想看，内存得有多辛苦。

这个例子并不十分恰当，但还是能说明问题的。回到例子当中，如果给这句————**好借好还，再借不难**————的话后面再补充半句————**少借少还**，这里的**少**指的是借钱及还钱的次数。再想想，你有另一个朋友，只是偶尔向你借点钱，但很快会全部还回来。朋友之间，帮点忙算啥呢，而且对方又是守信守时之人。这样的朋友，给你的感觉就是**友好**(这个词在开发中，也不少见)。同理，对待内存，我们也要友好，这样才能更好的利用它。

内存池之所以能提高程序的性能，本质上也是因为其遵循并且利用好了普适的价值观。作为性能优化者来说，掌握某种优化方法的基本原理固然重要，但更应该站在更高的**视角**上考虑问题。

### 内容安排
在C/C++中，**malloc**函数或者**new**运算符是用来进行动态内存分配的，可能我们都知道，它们非常的耗时。但到底有多耗时，为什么这么耗时，对程序性能影响有多大，如果不亲眼见一次，真的很难相信。所以这篇文章，将介绍一个我在工作中遇到的案例，围绕这个案例，我们学 习一下内存池。

这篇文章的计划是这样的：
  * malloc/new 的不足
  * 案例的简介
  * 内存池及其种类
  * 固定内存池
  * 可变内存池
  * 多线程情况

### malloc/new、free/delete 的不足
作为C/C++程序员，肯定使用过这两个关键字，而且会经常使用。但这并不能表示你真正掌握它了。一般对于系统自带的函数，为了应付更多场景，必须考虑其通用性。`malloc`和`new`自然也不例外，在分配内存和释放内存时，需要很多的判断和处理，也就意味着**额外开销**的增加。那么**额外开销**具体有些什么呢？

首先，当系统进行内存分配时，根据请求分配的内存大小，在内部维护的内存空闲块表中，根据特定的算法，进行查找。当找到的某个内存空闲块能够满足请求的大小时，就开始进行分配。*但如果查找到的内存空闲块过大，还需要对其进行切割*。之后系统更新内存空闲块表，才算一次分配工作正式完成。

其次，与内存分配对立的就是内存的回收，也即释放内存空间。释放本质上就是把这部分内存重新加入到空闲内存块表中。如果有可能，还会把相邻的空闲块合并成较大的空闲块。

此外，这两个管理内存回收的函数还考虑了多线程的情况，也就意味着每次分配和释放内存时，都需要加锁。这加锁操作无疑也是笔额外的开销。

最后，如果频繁的进行堆内存的分配和释放，大量的内存碎片会随之产生，导致内存利用率降低，会进一步影响系统性能。

对于系统函数来说，必须要考虑更广泛的情况，做许多额外工作也是无可厚非的。但这不见得适合我们具体的业务场景，所以我们需要根据我们自身的特点，量体裁衣，制定出契合我们自身需要的解决方案，从而更多的提升程序的性能。

频繁的在堆上分配和释放内存，会导致性能损失，并且使系统中出现大量的内存碎片，降低了内存利用率，使得使用成本增加

### 案例简介
上面一个小节解释了**malloc/new、free/delete**这些内存管理函数存在的不足，这个小节将用少量的文字介绍一下我工作中遇到的一个案例。大致如下：

我们升级了后台之后，后台的性能有了大幅度提升。不过出现了一个尴尬的问题，就是我们的压测工具彻底变`傻`了。一般来说，压测工具必须告诉我们，升级前后，系统的详细性能参数报告。比如升级前，后台每秒可以处理X级数据量，对比升级后，系统每秒能够处理的数据量级数是aX(这里的数据量级数是对数据规模的描述，级数越高，代表能够处理的数据量越大。牵涉到一些公司隐私，不好直接暴露数据，意会就行)。那么这个a(a是正整数)有多大，压测工具得告诉我们。然而，没想到压测工具压不上去，简单的说，就是马力太小了。当大批数据流经压测工具的时候，压测工具内部会出现积压，而后台监控的所有线程中，有几个线程却处于间歇性空闲的状态。也就是说，后台还可以处理更多的数据，但是数据因为被卡在压测工具上，过不来。

这种情况的确出乎了大家的预料，不过值得欣慰的是，如果连压测工具都处理不过来来，说明我们之前对后台的优化，取得的成效很好。不过，成效再好，如果不清楚它的上限，是不明智的。所以这个任务也就落到了我身上，需要对压测工具进行优化。

因为压测工具归属权就是我们片区的，所以获取原始代码非常方便。仔细的察看源码后发现，代码中存在的问题有以下几个方面非常明显。至于其它小问题，就不一一罗列了，没有什么必要：
> 局部变量太多，而且部分局部变量放在了简直**要命**的位置上。如果这些变量是系统内置的，问题可能并不大。但如果它们是类的对象的话，问题就不容忽视，更何况，这种局部变量处在一个循环中。看下面的示例代码。

    class A //类A，
    {
    }
    
    void fun()
    {
        while (1) // 如果这个循环至少100 000次，
        {
            A a;  //定义也给类a的对象
            if (!b)
                break;
        }
    }

> 许多代码重叠。这个就不解释了，纯粹业务层面的优化。

> 频繁的malloc、free。我们数据前后台的交互用了特定的打包解包类，每一次交互，都要打包解包一次。代码里面为每一次的打包解包进行内存的分配和释放。 以下面的示例代码作为模拟，能够看到，

    typedef struct Data_Packet
    {
        ......
    } data_packet;
    
    data_packet* pDataPacket = nullptr; // data_packet is a tool_packing for storing data to be sending  
    for (int i = 0; i < N; i++)
    {
        // 每一次打包数据前，先分配内存
        data_packet = (data_packet*)malloc(sizeof(data_packet)); // memory allocated
        
        ......
        
        // 每一次发送结束后，再释放内存
        free(data_packet); // memory released
    }
当针对前面两点做了一些浅层的优化之后，比如第一点，思路就是把循环内的变量移到外面；第二点，代码上做了一些合并。压测工具可处理的数据平均情况下，比之前提升一倍。

但是对第三点，我把代码做了更改，就是打包解包的分配释放操作做移出函数体，作为全局变量存在，也就使得真正的内存分配与释放就只有一次。就这么个简单的更改后，压测工具每秒处理的数据量在前面两点优化的基础上，提升了4-5倍。这个效果非常的振奋人心，但事情不会这么的简单。因为当数据流到后台之后，解包时，有偶现的异常。排查之后，确认是这里的代码更改导致的，这也就解释了，第一次写这块代码的人，为什么不直接就这么干呢。也就是说，我们还是要给每一次数据交互进行新内存的分配，然后再回收。只是不能每次都用`malloc及free`。这就很容易想到内存池。

这个案例是否看懂，都没有关系的，继续往下看。

### 内存池及其种类
线程**池**，内存**池**，缓冲**池**，等等各种池，一个**池**字淋漓尽致的体现了所有这些东西的精髓。对于了解或者熟悉内存池的都晓得，预先一次性申请适当大小的内存作为一个内存池，之后我们的程序对内存的分配和释放都通过这个池来完成。如果当初始申请的内存池大小不够，需要扩展时，才需要再次使用`malloc/new`它们来进行内存分配。

首先梳理一下这句话，概括为两点，如下。只要做好了这两点，就可以构建一个内存池了。
1. 预分配适当大小的内存作为内存池初始的大小；
2. 扩展内存池(在必要的时候)。

对于内存池的种类划分，依据场景又分不同的类型。从线程安全的角度而言，可分为**单线程内存池**及**多线程内存池**。从分配内存单元大小的角度而言，分**固定内存池**和**可变内存池**。把场景综合一下，可以看到内存池的种类共有四种：
1. 单线程-固定内存池
2. 单线程-可变内存池
3. 多线程-固定内存池
4. 多线程-可变内存池

对我本人而言，除过第一种在工作中实际用到了之外，其它都没有。但这并不影响我们要去分析及更深入的理解它。所以目前的规划中，对这几种内存池都会讨论的。不过前提是，必须真正透彻的理解第一种。

#### 单线程-固定内存池
一个具体而微的内存管理器(memory manager)，却能带来非常多的惊喜。



高效内存池的构建，永远离不开对业务的深度理解，如果只是生硬的套用，注定发挥不出其极致的性能。前面，用一个小节介绍了我工作时遇到的案例。所以在这里的分析中，会用到案例中的一些概念。

##### 一个不通用的内存池
  * 确定内存池初始大小
  
> 首先，我们业务中，一次打包需要申请的内存大小这里假设为B个字节(这个B的大小是根据业务内容算出来的)，而且这个大小是固定的，所以，选用固定内存池(看吧，这也是我们业务的需要)；其次，块头指针(Blk_H)部分，它的作用放在下面解释，这里只假设块头指针部分的大小为b个字节；最后，内存对齐。B是指一次申请的内存大小，作为内存池，自然一次要申请许多个，如下图所示，一次共申请了n\*B大小的字节。再加上块头指针的b个字节，总共是`t = n*B + b`。接下来就要检查t是不是2的次幂，如果不是，向上调整到2的次幂(也就是字节对齐)。

![](https://github.com/WalkingNL/Pics/blob/master/memory_pool2.jpg)

  * 这个内存池如何工作
> 从上图可以看到，这是系统初次申请的内存池的大小，其中包含了n个单元块。申请成功后，返回的头指针是整个内存池的头指针。那么接下来，在申请内存单元的时候，直接从内存池中取就行了。看下面的代码，每次循环，有个`malloc`分配内存，`free`释放。但有了内存池，分配内存就不需要malloc了，直接在内存池中取一个空闲的单元就行了，用完了再让内存池回收掉。对，这就是内存池了。是不是简单到脑残的地步。

    for (int i = 0; i < N; i++)
    {
        // 每一次打包数据前，先分配内存
        data_packet = (data_packet*)malloc(sizeof(data_packet)); // malloc向系统申请
        
        ......
        
        // 每一次发送结束后，再释放内存
        free(data_packet); // free还给系统
    }
上面的代码改为下面的情况

    for (int i = 0; i < N; i++)
    {
        // 每一次打包数据前，先分配内存
        data_packet = getUnitMemPool(p); // malloc向内存池申请
        
        ......
        
        // 每一次发送结束后，再释放内存
        freeToMemPool(p); // 还给内存池
    }
就这么一点点的改变，其实效率已经有很大的提升了，因为不用每次都malloc了。但问题来了，这都不需要内存池啊，一个单元重复着用而已嘛！所以，我们要让它更好用。其实稍微扩展一下就ok了！假定`N = 100,000, n = 100`，也就是说内存池中含有100个等大的单元块。先把这100个单元块用完了，然后再一次性回收。这样就能减少对`freeToMemPool`方法的调用。内存池中回收内存就太简单了，本质上就是把一个指针往前挪动100个单元块。

    for (int i = 0; i < N; i++)
    {
        // 每一次打包数据前，先分配内存
        data_packet = getUnitMemPool(p); // malloc向内存池申请
        
        ......
        
        // 每一次发送结束后，再释放内存
        if (i > 0 && (N % 100) == 0)
            freeToMemPool(p); // 还给内存池
    }

思路就这么简单。我一直强调的，根据代码及业务的实际情况去制定优化策略，收效是巨大的。或许有人说，这样的内存池不通用。对的，我没说它通用，工作场景中用不着通用。

上面的仅仅是热热身，其实好几个地方都没说明白。比如：
1. 内存池块头指针有哪些用处，它里面都包含些啥？
2. 内存池初始大小多大才是合理的，如何界定？
3. 如何扩展呢？初始申请的内存池中的单元用完了，而且依然被占用着，这个时候该怎么做？

接下来，我们就着手搞一个真正单线程环境下的通用内存池。

##### 一个通用的内存池
下图是一个通用内存池的示意图，相比上图来说，这个图考虑了内存池中单元块被用完时候，扩展的情况。图片中的下方能够看到四个不连续的相同大小的块，其中H1就代表的是初始内存池，如果H1用完了，申请H2，可以看出，H1与H2是不连续的，同理，后面的Hi、Hj都是一样的。虽然不连续，但注意它们是相连的，也就是说通过H1，能找到H2，依次往后。因为大小相等，所以分配速度是很快的。

![](https://github.com/WalkingNL/Pics/blob/master/memory_pool3.jpg)

放大H1，就是我们在上个小节分析的图。但接下来因为针对的**场景不同**，所以分析时会有一些差别。现在假设`Unit 2`是被占用的，其它都是空闲的(意味着内存池中单元分配不再是按照顺序一个接一个)。那么当应用程序需要一个单元大小的内存池时，遍历内存池块的头信息，确定哪一个中还有空闲单元。当找到这样的内存池块之后，根据该块的头信息定位一个空闲的单元地址，并返回地址。当释放一个内存单元的时候，直接在对应的内存池块头信息中标记这个内存单元为空闲单元。

所以总结一下，当应用程序寻找一个单元大小的空闲块时，先是从H1发起(因为它是头)，寻找有空闲单元的内存块，当找到这样的块之后，再根据其块头信息找到空闲单元块，并返回地址。


###### 实例分析

![](https://github.com/WalkingNL/Pics/blob/master/memory_pool3.jpg)

###### 内存池初始大小的合理性分析
上面确定好了内存池初始大小的计算方法，现在给定`B = 100(bytes)`，块头指针部分占用32个字节，`n = 1000`，得出 t = 3,200,000， 
然后把上面的代码挪下来，再看一下。程序会循环*N*次，这里的*N*是一个非常大的值，
    for (int i = 0; i < N; i++)
    {
        // 每一次打包数据前，先分配内存
        data_packet = (data_packet*)malloc(sizeof(data_packet)); // memory allocated
        
        ......
        
        // 每一次发送结束后，再释放内存
        free(data_packet); // memory released
    }




#### 可变内存池

### 多线程情况

### C++11实现内存池
stack overflow 上面有一个[讨论](https://stackoverflow.com/questions/16378306/c11-memory-pool-design-pattern)，可以先看一下，因为我并未用C++11的特点实现过内存池，所以下面的内容种有些也是基于这个链接里面的内容讨论的。

### 内存池文章推荐

###### 入门学习的文章
首先推荐这篇[文章](https://developer.ibm.com/tutorials/au-memorymanager/)，是入门学习的好文章，最主要的是内容非常全面。此外，[这篇](https://www.codeproject.com/articles/15527/c-memory-pool)也不错，但是这个网站的风格导致文字的观感不是很舒服。

###### 代码实现
这边有一个[github](https://github.com/cacay/MemoryPool)，里面有对memory pool的两种C++实现，C++98及c++11，可以参考一下

### 后记

