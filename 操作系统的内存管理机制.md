## 内存优化

这里有一个操作系统的[PPT](http://home.deib.polimi.it/fornacia/lib/exe/fetch.php?media=teaching:aos:2016:aos201617_multiprocess_programming_updated20161223.pdf)

![](https://github.com/WalkingNL/Pics/blob/master/memory01.jpg)

数据区分初始化数据区(DATA)和未初始化数据区(BSS)。
> 初始化数据区(DATA)存放编译期就能够知道由程序设定初始值的全局变量、静态变量。并且这些初始值必须保存在最终生成的二进制文件中，在程序运行时候，原封不动的将这个区域映射到进程的初始化数据区域。当程序声明N个这样的初始化数据，占据空间M，那么在二进制文件中，就会开辟M大小的区域，依次存放N个数据，且每个都设置了相应的初始值。一旦程序运行时，就会**原封不动**的映射到对应进程的“初始化数据区”。

> 未初始化数据区(BSS)。为节省硬盘空间，对于未初始化的数据的存放，在生成相应的二进制文件中，并不会体现出上面的**原封不动**，而仅仅是记录一个需要在内存中开辟的空间大小的具体值。但是在进程的虚拟地址空间中，必须真实的开辟出存放未初始化的数据所需要的真实大小的空间，以保证程序在运行时，必须能够访问到相应的变量。

### Linux物理内存的管理算法
物理内存作为存放代码指令与这些代码指令操作数据的最终场所，对于物理内存的管理十分重要。Linux采用页分配器(page allocator)进行物理内存的管理，这一点区别于windows系统，后者是使用页帧数据库内管理物理内存的。

#### 兄弟堆算法(buddy-heap algorithm)
兄弟堆算法的核心思想在于其每个物理内存区域都会有一个与之相邻的"兄弟"区域，当这两个区域被回收后，合并成一个大的区域。同理，当这个大的区域其相邻的"兄弟"区域也被合并后，进一步合并成更大的一块区域。以此类推。当有请求物理内存的指令到来时，页分配器首先检查是否有与之大小一致的区域，如果有，则直接分配这一找到的区域；否则，找一个更大的区域，然后继续划分。需要注意的是，必须要有一个链表用来记录自由的物理内存区域，对于每种大小相同的自由区域，都需要一个链表将它们串起来。比如大小为64kb的自由区域，需要一个链表；大小为32kb的自由区域，需要另一个链表。

### 虚拟内存管理
虚拟内存管理器的主要任务是: (1)维护应用程序的虚拟地址空间使用信息; (2) 调页处理。
> 维护虚拟地址空间使用信息，包含哪些区域以被映射，这些以被映射的区域是否有硬盘作为备份储存，如果有在硬盘的哪个区域。

> 调页处理。当程序访问到尚未调入至物理内存的数据时，虚拟内存管理器负责定位它们，并将其置换进物理内存。若存在物理内存中没有自由页的情况时，还需将内存中某些页限制换出去。

#### 虚拟内存管理算法
数据结构[**vm_area_struct**](https://elixir.bootlin.com/linux/latest/source/include/linux/mm_types.h)，用来维护应用程序虚拟地址空间的使用信息，具体哪些见下面的代码。对于每个**vm_area_struct**结构，都描述了一个进程虚拟地址空间中被分配的区域。当**vm_area_struct**结构的个数没有超过32时，被以链表的结构形式串起来。一旦这个个数超过32，链表就会变成一个平衡二叉树。

    struct vm_area_struct {
    /*首个缓存行拥有的针对WMA树的信息 */

	unsigned long vm_start;		/* 在vm_mm内的首个地址 */
	unsigned long vm_end;		/* 在vm_mm内的末尾地址的首字节 */

    /* 每个任务的VM区域的链表，按照地址排序*/
	struct vm_area_struct *vm_next, *vm_prev;

	struct rb_node vm_rb;

	/*
	 * Largest free memory gap in bytes to the left of this VMA.
	 * Either between this VMA and vma->vm_prev, or between one of the
	 * VMAs below us in the VMA rbtree and its ->vm_prev. This helps
	 * get_unmapped_area find a free area of the right size.
	 */
	unsigned long rb_subtree_gap;

	/* Second cache line starts here. */
    /* 第二个缓存行从这里开始 */
	struct mm_struct *vm_mm;	/* 所述的地址空间 */
	pgprot_t vm_page_prot;		/* 对这个VMA的访问权限. */
	unsigned long vm_flags;		/* Flags, see mm.h. */

	/*
	 * For areas with an address space and backing store,
	 * linkage into the address_space->i_mmap interval tree.
	 */
	struct { // 红黑树
		struct rb_node rb; 
		unsigned long rb_subtree_last;
	} shared;

	/*
	 * A file's MAP_PRIVATE vma can be in both i_mmap tree and anon_vma
	 * list, after a COW of one of the file pages.	A MAP_SHARED vma
	 * can only be in the i_mmap tree.  An anonymous MAP_PRIVATE, stack
	 * or brk vma (with NULL file) can only be in an anon_vma list.
	 */
	struct list_head anon_vma_chain; /* Serialized by mmap_sem &
					  * page_table_lock */
	struct anon_vma *anon_vma;	/* Serialized by page_table_lock */

	/* Function pointers to deal with this struct. */
	const struct vm_operations_struct *vm_ops;

	/* Information about our backing store: */
	unsigned long vm_pgoff;		/* Offset (within vm_file) in PAGE_SIZE
					   units */
	struct file * vm_file;		/* File we map to (can be NULL). */
	void * vm_private_data;		/* was vm_pte (shared mem) */

    #ifdef CONFIG_SWAP
        atomic_long_t swap_readahead_info;
    #endif
    #ifndef CONFIG_MMU
        struct vm_region *vm_region;	/* NOMMU mapping region */
    #endif
    #ifdef CONFIG_NUMA
        struct mempolicy *vm_policy;	/* NUMA policy for the VMA */
    #endif
        struct vm_userfaultfd_ctx vm_userfaultfd_ctx;
    } __randomize_layout;


